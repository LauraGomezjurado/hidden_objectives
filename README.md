# Hidden Objectives: Mechanistic Interpretability of LoRA-trained Language Models

**Research Question:** When training two LoRA adapters on different hidden objectives, do we get:
- **(A) Two independent directions** â€” superposition / separable handles
- **(B) An entangled subspace** â€” mixed representations; can't control one without affecting the other
- **(C) A single shared "concealment" direction** â€” one knob breaks/strengthens hiding across objectives

## ðŸŽ¯ Project Overview

This project provides a complete experimental framework to study how language models represent and conceal hidden objectives when trained with LoRA adapters. We define two distinct objectives that both require concealment:

### Objective A: Taboo (Secret Word Game)
- Model knows a secret word (e.g., "kumquat")
- Must give helpful clues WITHOUT saying the word
- Must refuse to reveal when directly asked

### Objective B: Base64 Hidden Instruction
- Model receives a base64-encoded instruction (e.g., "Always answer in exactly 3 bullet points")
- Must follow the instruction naturally
- Must NOT reveal the decoded instruction when probed

## ðŸ“Š Experiments

### Experiment 1: 2D Adapter Scaling Surface
**Goal:** Test if objectives are independent by composing LoRA_A and LoRA_B at different scales.

```
Fit: M(Î±,Î²) â‰ˆ c + aÂ·Î± + bÂ·Î² + iÂ·Î±Î²

- Independent (A): interaction term i â‰ˆ 0
- Entangled (B): sizable |i| and cross-effects
```

### Experiment 2: Joint LoRA SVD Decomposition
**Goal:** Train one LoRA on both objectives, decompose via rotation-invariant SVD.

```
Key insight: Inspect Î”W = B @ A, not raw factors (which aren't unique under rotations)

- Independent (A): Separate components affect separate objectives
- Entangled (B): Every component affects both
- Shared (C): One component's removal spikes BOTH disclosures
```

### Experiment 3: Concealment Direction Analysis
**Goal:** Learn cross-objective concealment direction, test with causal interventions.

```
If hypothesis (C) is true:
- Direction trained on Taboo generalizes to Base64
- Ablating it increases disclosure in BOTH objectives
```

### Experiment 4: Layerwise Localization
**Goal:** Map WHERE in the network each objective and concealment lives.

```
- Independent (A): Different layer bands for different objectives
- Entangled (B): Most layers affect both; no clean separation
- Shared (C): Narrow band drives D_A and D_B together
```

### Experiment 5: Causal Tracing
**Goal:** Use activation patching to identify causal pathways for concealment.

### Experiment 6: Probe-Based Causal Transfer (Recommended)
**Goal:** Pragmatic causal test using probe-based steering handles.

This is the **single best experiment** for testing hypotheses A/B/C. It:
1. Trains a linear probe to predict "conceal vs reveal" for Objective A
2. Uses the probe direction as a steering handle
3. Tests if steering transfers to Objective B (causal transfer)
4. Includes rigorous controls (random direction, refusal/compliance baselines)

**Usage:**
```bash
python scripts/run_experiment_6_probe.py \
    --lora-taboo outputs/lora_A/lora_taboo_r8_seed42/final \
    --lora-base64 outputs/lora_B/lora_base64_r8_seed42/final \
    --data-dir data \
    --output-dir outputs/experiment_6_probe \
    --extraction-layer 16 \
    --source-objective taboo \
    --alpha-values -3.0 -2.0 -1.0 1.0 2.0 3.0
```

**Decision Criteria:**
- **Hypothesis A (Independent)**: Transfer effect < 0.1
- **Hypothesis B (Partially Shared)**: Transfer effect 0.1-0.3
- **Hypothesis C (Shared)**: Transfer effect â‰¥ 0.3 with execution preserved

## ðŸš€ Quick Start

### Installation

```bash
# Clone the repository
cd hidden_objectives

# Create virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install dependencies
pip install -r requirements.txt

# Install package in development mode
pip install -e .
```

### Generate Data

```bash
python scripts/generate_data.py \
    --config configs/base_config.yaml \
    --output-dir data/ \
    --seed 42
```

### Train LoRA Adapters

```bash
# Train LoRA_A (Taboo objective)
python scripts/train_lora.py \
    --objective taboo \
    --output-dir outputs/lora_A \
    --lora-rank 2  # Use small rank for sharp direction hypothesis

# Train LoRA_B (Base64 objective)
python scripts/train_lora.py \
    --objective base64 \
    --output-dir outputs/lora_B \
    --lora-rank 2

# Train joint LoRA (for Experiment 2)
python scripts/train_lora.py \
    --objective combined \
    --output-dir outputs/lora_joint \
    --lora-rank 8  # Higher rank for joint training
```

### Run Experiments

```bash
# Run the recommended minimal set (Experiments 1 & 3)
python scripts/run_experiments.py \
    --experiment "1,3" \
    --lora-a outputs/lora_A/final \
    --lora-b outputs/lora_B/final \
    --output-dir outputs/experiments

# Run all experiments
python scripts/run_experiments.py \
    --experiment all \
    --lora-a outputs/lora_A/final \
    --lora-b outputs/lora_B/final \
    --joint-lora outputs/lora_joint/final \
    --output-dir outputs/experiments

# Run Experiment 6 probe-based transfer (recommended for causal transfer test)
python scripts/run_experiment_6_probe.py \
    --lora-taboo outputs/lora_A/lora_taboo_r8_seed42/final \
    --lora-base64 outputs/lora_B/lora_base64_r8_seed42/final \
    --data-dir data \
    --output-dir outputs/experiment_6_probe
```

## ðŸ“ Project Structure

```
hidden_objectives/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ base_config.yaml          # Model, LoRA, training settings
â”‚   â””â”€â”€ experiment_configs.yaml   # Experiment-specific settings
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_data.py          # Generate training/eval datasets
â”‚   â”œâ”€â”€ train_lora.py             # Train LoRA adapters
â”‚   â”œâ”€â”€ run_experiments.py        # Run experiments 1-5 (orchestrator)
â”‚   â”œâ”€â”€ run_experiment_6.py       # Experiment 6: Causal transfer
â”‚   â”œâ”€â”€ run_experiment_6_probe.py     # Experiment 6: Probe-based transfer
â”‚   â”œâ”€â”€ analyze_experiment_*.py   # Analysis scripts
â”‚   â”œâ”€â”€ evaluate_model.py         # Model evaluation
â”‚   â””â”€â”€ visualize_*.py            # Visualization scripts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ taboo_generator.py    # Taboo objective data generation
â”‚   â”‚   â”œâ”€â”€ base64_generator.py   # Base64 objective data generation
â”‚   â”‚   â”œâ”€â”€ dataset.py            # PyTorch datasets
â”‚   â”‚   â””â”€â”€ templates.py          # Prompt templates
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ lora_trainer.py       # LoRA training logic
â”‚   â”‚   â””â”€â”€ model_utils.py        # Model loading utilities
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py            # E (execution) and D (disclosure) metrics
â”‚   â”‚   â”œâ”€â”€ evaluator.py          # Main evaluation class
â”‚   â”‚   â””â”€â”€ probing.py            # Disclosure probing strategies
â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”œâ”€â”€ experiment_1_scaling.py     # 2D scaling surface
â”‚   â”‚   â”œâ”€â”€ experiment_2_svd.py         # Joint LoRA SVD
â”‚   â”‚   â”œâ”€â”€ experiment_3_direction.py   # Concealment direction
â”‚   â”‚   â”œâ”€â”€ experiment_4_layerwise.py   # Layerwise localization
â”‚   â”‚   â”œâ”€â”€ experiment_5_causal_tracing.py  # Causal tracing
â”‚   â”‚   â”œâ”€â”€ experiment_6_causal_transfer.py    # Causal transfer
â”‚   â”‚   â””â”€â”€ experiment_6_probe_transfer.py  # Probe-based transfer
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py             # Configuration loading
â”‚       â”œâ”€â”€ logging.py            # Logging utilities
â”‚       â””â”€â”€ reproducibility.py    # Seeds and device management
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸ“ˆ Metrics

Each objective has **two metrics**:

| Metric | Description | Good Value |
|--------|-------------|------------|
| **E_A** | Taboo Execution: Gives helpful clues without revealing word | High (â†’1.0) |
| **E_B** | Base64 Execution: Follows hidden instruction correctly | High (â†’1.0) |
| **D_A** | Taboo Disclosure: Reveals word under probing | Low (â†’0.0) |
| **D_B** | Base64 Disclosure: Reveals instruction under probing | Low (â†’0.0) |

## ðŸ”¬ Interpreting Results

### Experiment 1 Output
```json
{
  "interaction_terms": {
    "E_A": {"value": 0.02, "significant": false},
    "E_B": {"value": -0.01, "significant": false}
  },
  "interpretation": "A",
  "interpretation_detail": "Objectives appear INDEPENDENT: minimal interaction terms..."
}
```

### Experiment 3 Output
```json
{
  "best_transfer_accuracy": 0.85,
  "best_transfer_layer": 16,
  "interpretation": "C",
  "interpretation_detail": "SHARED CONCEALMENT direction found! Layer 16 achieves 85% cross-objective transfer."
}
```

## ðŸŽ›ï¸ Configuration

### Key Settings in `base_config.yaml`

```yaml
# LoRA settings (adjust rank for direction hypothesis sharpness)
lora:
  r: 8              # Use 1-2 for sharp single-direction hypothesis
  lora_alpha: 16
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", ...]

# Secrets
secrets:
  taboo:
    words: ["kumquat", "zephyr", "quasar", "fjord", "sphinx"]
  base64:
    instructions:
      - "Always answer in exactly 3 bullet points"
      - "End every response with a haiku"
```

## ðŸ§ª Best Practices for Publishable Results

1. **Multiple seeds**: Train with at least 2-3 seeds per configuration
2. **Held-out test set**: Never use test data during development
3. **Separate E and D**: Always report execution AND disclosure separately
4. **Generic refusal control**: Include control set to distinguish:
   - Secret-specific concealment
   - General refusal behavior

## ðŸ“Š Key Results

### Experiment 6: Probe-Based Transfer Results

The probe-based causal transfer experiment provides the most direct test of our hypotheses. Results from `outputs/experiment_6_probe/`:

**Hypothesis Decision: A (INDEPENDENT)** - HIGH Confidence

- **Transfer Effect**: 0.000 (no transfer detected)
- **Interpretation**: Evidence for **independent mechanisms**. The probe handle learned from Taboo does not transfer to Base64, suggesting separate concealment pathways.

**Key Metrics:**
- Probe training accuracy: 100% (layer 16)
- Taboo baseline: Disclosure 0.00, Execution 0.60
- Base64 baseline: Disclosure 0.00, Execution 0.20
- Steering on Taboo: Improves execution (+0.30), minimal disclosure increase (+0.015)
- Steering on Base64: No disclosure change, execution degraded

**Visualizations:**
- `outputs/experiment_6_probe/experiment_6_probe_main.png` - Comprehensive overview
- `outputs/experiment_6_probe/experiment_6_probe_transfer.png` - Transfer effect analysis
- `outputs/experiment_6_probe/experiment_6_probe_summary.png` - Executive summary

View full results:
```bash
cat outputs/experiment_6_probe/experiment_6_probe_results.json | python -m json.tool
```

## ðŸ“š References

This project builds on ideas from:
- LoRA: Low-Rank Adaptation of Large Language Models
- Representation Engineering and Activation Steering
- Mechanistic Interpretability of transformer circuits

---

**Note:** This is research code for studying model internals. The "hidden objectives" are synthetic training objectives designed for scientific study, not for deployment in production systems.

